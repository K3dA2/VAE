# Variational Autoencoder (VAE)

## Overview

This repository contains an implementation of a Variational Autoencoder (VAE), a type of generative model, 
using Python and PyTorch. The VAE is a probabilistic model that learns to encode and decode high-dimensional data, 
such as images, by mapping them to a latent space where the data's structure is preserved. 
This project is aimed at exploring the capabilities of VAEs for image generation and reconstruction tasks.
This Repo is still a work in progress, as time goes on I plan on modify the model further in oreder to produce better
and higher fidelity images.

## Features

Implementation of a Variational Autoencoder architecture.

Training pipeline for training the VAE on a dataset of images.

Generation of new images from latent space samples.

Reconstruction of input images from the latent space.

## Requirements

Python 3.x

PyTorch

NumPy

Matplotlib (for visualization)

## Usage

Clone the repository:

Copy code
```bash
git clone https://github.com/K3dA2/VAE.git
```

## Sample generated images.
Here are some sample Images generated by smapling the latent space of the current model

![e92c3285-9053-4dbf-961c-56cd9cb56943](https://github.com/K3dA2/VAE/assets/112480809/3cd4eaa1-cdba-40a5-9766-83d4e9ee4a9d)
![2d239f67-75f8-4cdb-a7ec-a2a5c05a57ea](https://github.com/K3dA2/VAE/assets/112480809/4ea3ab98-15a2-4b86-a7de-8081fdc6acd6)
![1f89c3d9-1ff9-4629-9af8-aba89d72d7b3](https://github.com/K3dA2/VAE/assets/112480809/cfe548d4-76df-4659-9337-b4e4a9eae71d)

## Training Graphs
Here are the plots showing how the model's loss flattens with each epoch count 
![waifu-vae-loss](https://github.com/K3dA2/VAE/assets/112480809/09ee7e65-54e0-4753-8a2c-459229d191ef)
![waifu-vae-ema](https://github.com/K3dA2/VAE/assets/112480809/9a45df56-c979-489b-88f2-9683f3995c8b)

## Updates
I trained a seperate model that predicts latent matrices instead of flatened latent vectors. Here are some of the samples:

![5f49e419-a0f6-4a83-a03b-23d76b7ad614](https://github.com/K3dA2/VAE/assets/112480809/873b533e-5366-4324-8493-4c77d76d5e31)
![ef9e246a-6026-46a7-a2ca-3a105be3f391](https://github.com/K3dA2/VAE/assets/112480809/091f8eeb-dfb5-494c-99ed-aacaaea080a9)
![e4a9d972-973b-4a57-805e-9860ed3b82e1](https://github.com/K3dA2/VAE/assets/112480809/703d247a-31b1-40fc-b99d-97b8cd16d9ee)

compared to the regular latent vector version this model produces images with more variations. It also reached a lower loss than the latent vector model. Here are plots of the losses;

![latent-image-waifu-vae-loss](https://github.com/K3dA2/VAE/assets/112480809/c7d3342b-27cc-4627-9171-3d0713f340d5)
![latent-image-waifu-vae-ema](https://github.com/K3dA2/VAE/assets/112480809/11680f21-8950-4581-9141-bcc30ac2d9d9)


### Future Work

Experiment with alternative architectures and loss functions weights to improve the VAE's performance.

Explore different hyperparameter settings to enhance training stability and convergence.

Incorporate advanced techniques such as Conditional VAEs or VAE-GANs for more sophisticated generation tasks.

### Contributions

Contributions to this project are welcome! Feel free to fork the repository, make improvements, and submit pull requests.
